{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Spam from Data\n",
    "Cleans the data for topic modelling\n",
    "\n",
    "## Data Sources\n",
    "- youbemom-merged.db (scraped with 1-Scrape_Forum.ipynb)\n",
    "\n",
    "\n",
    "## Changes\n",
    "- 2020-12-23: Created\n",
    "- 2021-01-18: Updated spam detection\n",
    "- 2021-01-25: Filtering spam words \n",
    "\n",
    "## TODO\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from youbemom import create_connection\n",
    "import re\n",
    "from math import floor\n",
    "from tqdm.notebook import tqdm\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import FileIO\n",
    "# saving the corpus and dictionary\n",
    "from gensim import corpora, models\n",
    "import pickle\n",
    "# topic models\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n",
    "# my functions\n",
    "from scraping import create_connection\n",
    "from lemmatize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old pattern = r'(http|ftp|https):\\/\\/[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "url_pattern = r'''((http|ftp|https):\\/\\/)[-a-zA-Z0-9:%\\._\\+~#=]{1,256}\\.[a-zA-Z0-9\\(\\)]{1,8}\\b([-a-zA-Z0-9<>\\*\\^\\(\\)@:%\\!,\\[\\]\\{\\}\\|'\"_\\+\\.~#\\?&/=]*)|(www\\.)*[-a-zA-Z0-9@:%\\._\\+~#=]{1,256}\\.(com|be|io|org|net)\\b([-a-zA-Z0-9<>\\*\\^\\(\\)@:%\\!,\\[\\]\\{\\}\\|'\"_\\+\\.~#\\?&/=]*)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_cutoff_pattern = r'''((http|ftp|https):\\/\\/)[-a-zA-Z0-9:%\\._\\+~#=]{1,256}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_pattern = r'([-a-zA-Z0-9_\\.\\+]+@[-a-zA-Z0-9]+\\.[-a-zA-Z0-9\\.]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_number_pattern = r'\\b[\\+\\-x0-9]*\\d{9,}(?<!0{7})\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_pattern = r'- no subject -'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_pattern = r'[a-zA-Z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lonely_number_pattern = r'^[0-9]+$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(conn):\n",
    "    \"\"\" gets the size of the data set in number of rows\n",
    "    :param conn: connection the the db\n",
    "    :return size: size of the posts table\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(''' SELECT COUNT(message_id) FROM posts ''')\n",
    "    size = cur.fetchone()\n",
    "    if size:\n",
    "        return int(size[0])\n",
    "    raise SystemExit(\"No size found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(chunksize):\n",
    "    \"\"\" read data in chunks from the table, format the text,\n",
    "        apply the sentiemnt analyzer, and write chunks to \n",
    "        the sentiment table\n",
    "    :param sql: selects columns of the posts table\n",
    "    :param chunksize: size of chunks\n",
    "    \"\"\"\n",
    "    sql = ''' SELECT message_id, title, body FROM posts '''\n",
    "    reader = pd.read_sql_query(sql,\n",
    "                               conn,\n",
    "                               chunksize=chunksize)\n",
    "    for i, df in enumerate(tqdm(reader)):\n",
    "        df = process_text(df)\n",
    "        df = add_spam_dummies(df)\n",
    "        df = probable_spam(df)\n",
    "        df = df[['message_id', 'text', 'text_clean', 'probable_spam']]\n",
    "        if i == 0:\n",
    "            df.to_sql('text', conn, if_exists='replace', index=False)\n",
    "        else:\n",
    "            df.to_sql('text', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text(df):\n",
    "    \"\"\" creates text column from\n",
    "        title and body\n",
    "    :param df: data frame\n",
    "    :return df: formatted data frame\n",
    "    \"\"\"\n",
    "    df['title'] = df['title'].replace('This post has been deleted\\.', '', regex=True)\n",
    "    df['text'] = df['title'] + \" \" + df['body']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_url(df):\n",
    "    \"\"\" finds urls in text strings and creates\n",
    "        new column of whether text has a url\n",
    "    :param df: data frame\n",
    "    :return df: formatted data frame\n",
    "    \"\"\"\n",
    "    regex_pat = re.compile(url_pattern, flags=re.IGNORECASE)\n",
    "    df['has_url'] = df['text'].str.contains(regex_pat)\n",
    "    regex_pat = re.compile(url_cutoff_pattern, flags=re.IGNORECASE)\n",
    "    df['has_cutoff_url'] = df['text'].str.contains(regex_pat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(df):\n",
    "    \"\"\" removes urls and cutoff urls from text strings and creates\n",
    "        new column of text without urls\n",
    "    :param df: data frame\n",
    "    :return df: formatted data frame\n",
    "    \"\"\"\n",
    "    regex_pat = re.compile(url_pattern, flags=re.IGNORECASE)\n",
    "    df['text_clean'] = df['text'].str.replace(regex_pat, \"\")\n",
    "    regex_pat = re.compile(url_cutoff_pattern, flags=re.IGNORECASE)\n",
    "    df['text_clean'] = df['text_clean'].str.replace(regex_pat, \"\")\n",
    "    df['text_clean'] = df['text_clean'].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_no_subject(df):\n",
    "    \"\"\" removes - no subject - from clean text strings\n",
    "    :param df: data frame\n",
    "    :return df: formatted data frame\n",
    "    \"\"\"\n",
    "    regex_pat = re.compile(subject_pattern, flags=re.IGNORECASE)\n",
    "    df['text_clean'] = df['text_clean'].str.replace(regex_pat, \"\")\n",
    "    df['text_clean'] = df['text_clean'].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_email(df):\n",
    "    regex_pat = re.compile(email_pattern, flags=re.IGNORECASE)\n",
    "    df['has_email'] = df['text'].str.contains(regex_pat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def has_large_number(df):\n",
    "    regex_pat = re.compile(large_number_pattern, flags=re.IGNORECASE)\n",
    "    df['has_large_number'] = df['text_clean'].str.contains(regex_pat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_alpha(df):\n",
    "    regex_pat = re.compile(alpha_pattern, flags=re.IGNORECASE)\n",
    "    df['has_alpha'] = df['text_clean'].str.contains(regex_pat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_lonely_numbers(df):\n",
    "    regex_pat = re.compile(lonely_number_pattern, flags=re.IGNORECASE)\n",
    "    df['text_clean'] = df['text_clean'].str.replace(regex_pat, \"\")\n",
    "    df['text_clean'] = df['text_clean'].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_emptys(df):\n",
    "    df['text_clean'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['text_clean'], inplace=True)\n",
    "    df.drop('title', axis=1, inplace=True)\n",
    "    df.drop('body', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_punctuation(df):\n",
    "    pattern = r'[-\\w\\s\\.,/:;!\\?\\'\\\"â€™]'\n",
    "    regex_pat = re.compile(pattern, flags=re.IGNORECASE)\n",
    "    df['n_symbols'] = df['text_clean'].str.replace(regex_pat, \"\").str.len()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_word(df, word, name=None, ignorecase=True):\n",
    "    if ignorecase:\n",
    "        regex_pat = re.compile(word.lower(), flags=re.IGNORECASE)\n",
    "    else:\n",
    "        regex_pat = re.compile(word)\n",
    "    if name:\n",
    "        df[name] = df['text'].str.contains(regex_pat)\n",
    "    else:\n",
    "        df[word] = df['text'].str.contains(regex_pat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(df):\n",
    "    df = create_text(df)\n",
    "    df = has_url(df)\n",
    "    df = remove_urls(df)\n",
    "    df = has_email(df)\n",
    "    df = has_large_number(df)\n",
    "    df = remove_no_subject(df)\n",
    "    df = count_non_punctuation(df)\n",
    "    df['text_length'] = df['text'].str.len()\n",
    "    df['text_clean_length'] = df['text_clean'].str.len()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spam_dummies(df):\n",
    "    for s in spam:\n",
    "        df = has_word(df, s)\n",
    "    df = has_word(df, r'\\[url', name=\"bracket_url\")\n",
    "    df = has_word(df, r'^Http', name=\"Http\", ignorecase=False)\n",
    "    df = has_word(df, r's\\.t\\.r\\.e\\.a\\.m', name=\"s.t.r.e.a.m\")\n",
    "    df = has_word(df, r'''\\bdd['s]*\\b''', name=\"has_dd\", ignorecase=False)\n",
    "    df = has_word(df, r'''\\bdh['s]*\\b''', name=\"has_dh\", ignorecase=False)\n",
    "    df = has_word(df, r'''\\bds['s]*\\b''', name=\"has_ds\", ignorecase=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probable_spam(df):\n",
    "    df['probable_spam'] = (\n",
    "        (df.vashikaran) |\n",
    "        ((~df.has_url) & df.has_large_number & df.text_length > 900) |\n",
    "        ((~df.has_url) & df.has_large_number & df.n_symbols > 10) |\n",
    "        ((~df.has_url) & df.has_large_number & df[\"problem.solution\"]) | \n",
    "        (df.has_url & df.vs & df.stream) |\n",
    "        (df.has_url & df[\"s.t.r.e.a.m\"]) |\n",
    "        (df.has_url & df.has_large_number) |\n",
    "        (df.has_url & df[\"visit.here\"]) |\n",
    "        (df.has_url & df[\"visit.at\"]) |\n",
    "        (df.has_url & df[\"amino.app\"]) |\n",
    "        (df.has_url & df[\"male.enhancement\"]) |\n",
    "        (df.has_url & df.testosterone) |\n",
    "        (df.has_url & df[\"visit.us.at\"]) |\n",
    "        (df.has_url & df[\"cbd.oil\"]) |\n",
    "        (df.has_url & df.Http) |\n",
    "        (df.has_url & df.bracket_url) |\n",
    "        (df.has_url & df.keto & df.text_length > 320) |\n",
    "        (df.has_url & df.supplement & df.text_length > 320) |\n",
    "        (df.has_url & df.pills & df.text_length > 320)\n",
    "    ) & (\n",
    "        (~df.has_dd) & (~df.has_dh) & (~df.has_ds)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get random sample of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(count, seed):\n",
    "    sql = ''' SELECT message_id\n",
    "        FROM posts\n",
    "        WHERE deleted=0\n",
    "    '''\n",
    "    conn = create_connection(path_db)\n",
    "    ids = pd.read_sql_query(sql, conn)\n",
    "    ids = ids.sample(n = count, random_state = seed)\n",
    "    temp_table_sql = ''' \n",
    "        DROP TABLE IF EXISTS temp;\n",
    "        CREATE TEMPORARY TABLE\n",
    "            temp(id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE, message_id INTEGER);\n",
    "    '''\n",
    "    cur = conn.cursor()\n",
    "    cur.executescript(temp_table_sql)\n",
    "    ids.to_sql('temp', conn, if_exists='replace', index=False)\n",
    "    select_sql = '''\n",
    "        SELECT\n",
    "            p.message_id AS message_id,\n",
    "            p.title AS title,\n",
    "            p.body AS body\n",
    "        FROM posts AS p\n",
    "        WHERE p.message_id IN (SELECT message_id FROM temp)\n",
    "    '''\n",
    "    samp = pd.read_sql_query(select_sql, conn)\n",
    "    conn.close()\n",
    "    return samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "path_db = str(path_parent / \"database\" / \"youbemom-merged.db\")\n",
    "# spam data\n",
    "path_spam_sample = str(path_parent / \"clean_data\" / \"spam_sample_{}.txt\")\n",
    "path_spam_words = str(path_parent / \"clean_data\" / \"spam_words.csv\")\n",
    "path_spam_forum = str(path_parent / \"clean_data\" / \"{}_spam.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample of Data\n",
    "Code on training data set and test on test data set. Randomly select data based on seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000000\n",
    "seed = 546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample(count, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = process_text(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Spam Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(path_spam_words)\n",
    "spam = spam['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in spam:\n",
    "    sample = has_word(sample, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = has_word(sample, r'\\[url', name=\"bracket_url\")\n",
    "sample = has_word(sample, r'^Http', name=\"Http\", ignorecase=False)\n",
    "sample = has_word(sample, r's\\.t\\.r\\.e\\.a\\.m', name=\"s.t.r.e.a.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = has_word(sample, r'''\\bdd['s]*\\b''', name=\"has_dd\", ignorecase=False)\n",
    "sample = has_word(sample, r'''\\bdh['s]*\\b''', name=\"has_dh\", ignorecase=False)\n",
    "sample = has_word(sample, r'''\\bds['s]*\\b''', name=\"has_ds\", ignorecase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample.to_csv(path_spam_sample.format(str(seed)), sep ='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded spam sample into Excel and hand-coded spam. There is minimal spam where there is no url and is always accompanied by some other indicator of spam (a long number that is probably a phone number, many non-punctuation symbols, or a specific word). I coded all urls in the first 100,000 messages in the sample, founding common key words and other idnicators. I checked this against the remaining urls in 1.2.5-Clean_Data-Identify_Spam.R, validating the spam indicators. This was used to create probable_spam function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probable Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = probable_spam(sample)\n",
    "sample['probable_spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "Loop through the dataframe, creating text, text_no_url, text_clean, and probable_spam in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not run above:\n",
    "spam = pd.read_csv(path_spam_words)\n",
    "spam = spam['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = get_size(conn)\n",
    "nchunks = 100\n",
    "chunksize = floor(size / nchunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e58324f5374675875e39a9d219fd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data(chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marked Spam Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_select = '''\n",
    "    SELECT message_id\n",
    "    FROM posts\n",
    "    WHERE family_id=?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_update = '''\n",
    "    UPDATE text\n",
    "    SET probable_spam=1\n",
    "    WHERE message_id=?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = \"school\"\n",
    "spam = pd.read_csv(path_spam_forum.format(sf))\n",
    "spam.fillna(0, inplace=True)\n",
    "spam = spam[spam['is_spam'] > 0.0]\n",
    "spam = spam['family_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46885 105409987\n",
      "401749 109324345\n",
      "439951 109779679\n",
      "442217 109803051\n",
      "443595 109820163\n",
      "449521 109886994\n",
      "449522 109886995\n",
      "457062 109973871\n",
      "457063 109973872\n",
      "464794 110059424\n",
      "477287 110186461\n",
      "522972 110714127\n",
      "522974 110714129\n",
      "522975 110714130\n",
      "522978 110714133\n",
      "522992 110714178\n",
      "538073 110889261\n",
      "559821 111142462\n",
      "559822 111142463\n",
      "559823 111142464\n",
      "559825 111142467\n",
      "560882 111153302\n",
      "573921 111302444\n",
      "599786 111599416\n",
      "602615 111630852\n",
      "603678 111644283\n",
      "613610 111763722\n",
      "624442 111882255\n",
      "625564 111895167\n",
      "628509 111929042\n",
      "632697 111973913\n",
      "656728 112245593\n",
      "656730 112245605\n",
      "656734 112245634\n",
      "680863 112512368\n",
      "689182 112605962\n",
      "698058 112705908\n",
      "702866 112759595\n",
      "719980 112950118\n",
      "726478 113012350\n",
      "737191 113131723\n",
      "740985 113174052\n",
      "743806 113206455\n",
      "748262 113254198\n",
      "749461 113268221\n",
      "750530 113279586\n",
      "754110 113322308\n",
      "754217 113322963\n",
      "755360 113336372\n",
      "758029 113366989\n",
      "759599 113385067\n",
      "760708 113398483\n",
      "761953 113412219\n",
      "761956 113412228\n",
      "763258 113426759\n",
      "765460 113452269\n",
      "768715 113489239\n",
      "769999 113504486\n",
      "771265 113518489\n",
      "775682 113569775\n",
      "781173 113630257\n",
      "785885 113678249\n",
      "787652 113694700\n",
      "796081 113778337\n",
      "797329 113792982\n",
      "797353 113793011\n",
      "803315 113855076\n",
      "810751 113937132\n",
      "813730 113968964\n",
      "818224 114016487\n",
      "820376 114038030\n",
      "823353 114070618\n",
      "831916 114156446\n",
      "831916 114631177\n",
      "831942 114156501\n",
      "831942 114156532\n",
      "836409 114204722\n",
      "836465 114204845\n",
      "847530 114315651\n",
      "855671 114403092\n",
      "857197 114419661\n",
      "858753 114437106\n",
      "860179 114453097\n",
      "860179 114453108\n",
      "860179 114453112\n",
      "863920 114492545\n",
      "863921 114492546\n",
      "870643 114569794\n",
      "870643 114569797\n",
      "873632 114602206\n",
      "873636 114602251\n",
      "873638 114602279\n",
      "878167 114647171\n",
      "879659 114664168\n",
      "885770 114726596\n",
      "887335 114745392\n",
      "897392 114848273\n",
      "900657 114884752\n",
      "904872 114934483\n",
      "907213 114961391\n",
      "913151 115022855\n",
      "922923 115124999\n",
      "922997 115125154\n",
      "926739 115160900\n",
      "939543 115278640\n",
      "950687 115386197\n",
      "950688 115386198\n",
      "950865 115387842\n",
      "966918 115520913\n",
      "996987 115788477\n",
      "1012727 115943063\n",
      "1017732 115990772\n",
      "1034268 116157878\n",
      "1049547 116313777\n",
      "1049547 116314129\n",
      "1055762 116375334\n",
      "1070177 116528791\n",
      "1084744 116681413\n",
      "1100885 116842449\n",
      "1143228 117270369\n",
      "1145653 117293972\n",
      "1145668 117294063\n",
      "1150846 117349208\n",
      "1161827 117466641\n",
      "1161827 117466672\n",
      "1235727 118264127\n",
      "1235727 118264144\n",
      "1374280 119703010\n",
      "1383123 119792134\n",
      "1400533 119966712\n",
      "1403610 119995582\n",
      "1403610 119995594\n",
      "1417260 120099395\n",
      "1437156 120298253\n",
      "1437257 120298895\n",
      "1438852 120316870\n",
      "1443104 120361789\n",
      "1443127 120361826\n",
      "1444865 120381256\n",
      "1448929 120427239\n",
      "1448931 120427250\n",
      "1448931 120427291\n",
      "1448931 120427467\n",
      "1448931 120427606\n",
      "1454141 120482555\n",
      "1485450 75926841\n",
      "1597921 77261897\n",
      "1602694 77319364\n",
      "1610662 77389323\n",
      "1610663 77389333\n",
      "1615698 77445873\n",
      "1626149 77569228\n",
      "1626149 77569262\n",
      "1626149 77569305\n",
      "1626151 77569241\n",
      "1626151 77569288\n",
      "1626152 77569242\n",
      "1626152 77569260\n",
      "1781918 79480867\n",
      "1783061 79495328\n",
      "1783061 79495343\n",
      "1783061 79495348\n",
      "1783061 79495556\n",
      "1855487 80399499\n",
      "1855487 80502342\n",
      "1855487 80649871\n",
      "1908662 81063815\n",
      "1908662 81063896\n",
      "1908662 81063922\n",
      "1965038 81757289\n",
      "2025643 82499999\n",
      "2041789 82696853\n",
      "2041789 82696879\n",
      "2041789 82698366\n",
      "2044864 82734679\n",
      "2060888 82930229\n",
      "2060894 82930305\n",
      "2060894 82930375\n",
      "2171579 84222749\n",
      "2171581 84222765\n",
      "2171583 84222772\n",
      "2263263 85323789\n",
      "2263263 85323883\n",
      "2263287 85324177\n",
      "2263287 85324213\n",
      "2263287 85324282\n",
      "2263287 85324326\n",
      "2263287 85324425\n",
      "2263287 85324487\n",
      "2263287 85324566\n",
      "2263287 85324608\n",
      "2263287 85324918\n",
      "2263287 85324526\n",
      "2263287 85324533\n",
      "2313523 85910835\n",
      "2313526 85910866\n",
      "2313531 85910913\n",
      "2313531 85911187\n",
      "2321608 86013214\n",
      "2324590 86048409\n",
      "2353927 86404340\n",
      "2353927 86404344\n",
      "2353927 86404350\n",
      "2353927 86404363\n",
      "2353927 86404376\n",
      "2353927 86404458\n",
      "2353927 86404500\n",
      "2353927 86404508\n",
      "2353927 86404502\n",
      "2353933 86404400\n",
      "2361471 86498124\n",
      "2376355 86679897\n",
      "2376361 86679931\n",
      "2376362 86679939\n",
      "2454404 87635114\n",
      "2504354 88249838\n",
      "2504354 88249846\n",
      "2506361 88274885\n",
      "2515999 88393948\n",
      "2639592 89934487\n",
      "2729085 91007508\n",
      "2789011 91688971\n",
      "3031839 94510427\n",
      "3072249 94965245\n",
      "3093915 95206558\n",
      "3093917 95206563\n",
      "3094942 95218141\n",
      "3105073 95333635\n",
      "3105089 95333720\n",
      "3205704 96424020\n",
      "3205704 96424164\n",
      "3211524 96488321\n",
      "3211524 96488446\n",
      "3211524 96488766\n",
      "3220940 96594911\n",
      "3249731 96891277\n",
      "3291586 97302710\n",
      "3291586 97302725\n",
      "3291586 97302731\n",
      "3291586 97302735\n",
      "3291586 97302745\n",
      "3291586 97302751\n",
      "3291586 97302762\n",
      "3291586 97302772\n",
      "3302833 97427893\n",
      "3302834 97427900\n",
      "3471843 99175512\n",
      "3553891 100020892\n",
      "3553891 100020893\n",
      "3553891 100509085\n",
      "3600599 100543110\n",
      "3600599 100543157\n",
      "3600599 100543207\n",
      "3600599 100543406\n",
      "3600599 100543432\n",
      "3604688 100586024\n",
      "3614447 100690835\n",
      "3614447 100690853\n",
      "3614447 100690923\n",
      "3622757 100769229\n",
      "3759047 102227637\n",
      "4025236 120828639\n",
      "4043273 121020891\n"
     ]
    }
   ],
   "source": [
    "for family_id in spam:\n",
    "    cur.execute(sql_select, (family_id,))\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        message_id = row[0]\n",
    "        print(family_id, message_id)\n",
    "        cur.execute(sql_update, (message_id,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
