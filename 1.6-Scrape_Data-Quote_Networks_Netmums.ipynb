{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quotes to Network\n",
    "This notebook takes the quotes table from the individual netmums databases and creates a network edge table that connects quoting and quoted posts.\n",
    "\n",
    "## TODO\n",
    "- To connect quotes (network graphs) between posts, I still need to identify which post is quoting what post. The issues that remain are:\n",
    " - Duplicate posts by quoted user so can't match text to a unique post\n",
    " - Links as ::link_1:: are common as the only text in a quote\n",
    " - Currently excluding anonymous posts\n",
    "- Finish `for` loop for quote chunks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from scraping import create_connection\n",
    "from netmums import set_up_merged_db\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]\n",
    "path_db = str(path_parent / \"database\" / \"netmums0{}.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(n_row, chunk_size):\n",
    "    \"\"\" create chunks of the correct size to portion the\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    n = math.ceil(n_row / chunk_size)\n",
    "    chunk_list = []\n",
    "    for i in range(n):\n",
    "        list_min = i * 100000\n",
    "        list_max = (i + 1) * 100000 - 1\n",
    "        if list_max > n_row:\n",
    "            list_max = n_row\n",
    "        chunk_list.append((list_min, list_max))\n",
    "    return(chunk_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database connection and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_table_sql = ''' \n",
    "#     CREATE TEMPORARY TABLE\n",
    "#         temp(\n",
    "#             id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "#             thread_id TEXT,\n",
    "#             post_count INTEGER,\n",
    "#             quoting_id TEXT,\n",
    "#             quoted_id TEXT,\n",
    "#             quoted_user TEXT,\n",
    "#             quoted_text TEXT,\n",
    "#             citation_n INTEGER\n",
    "#         );\n",
    "# '''\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(temp_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_sql = ''' DROP TABLE IF EXISTS temp; '''\n",
    "quotes_sql = '''\n",
    "    SELECT *\n",
    "    FROM quotes\n",
    "    WHERE quoted_id=\"\";\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_matches_sql = \"\"\"\n",
    "SELECT\n",
    "    q.thread_id AS quoting_thread_id,\n",
    "    q.post_count AS quoting_post_count,\n",
    "    q.quoted_text AS quoted_text,\n",
    "    q.citation_n AS citation_n,\n",
    "    s.thread_id AS quoted_thread_id,\n",
    "    s.post_count AS quoted_post_count,\n",
    "    s.body\n",
    "FROM (\n",
    "    SELECT\n",
    "        thread_id,\n",
    "        post_count,\n",
    "        quoted_user,\n",
    "        quoted_text,\n",
    "        citation_n\n",
    "    FROM temp\n",
    "    WHERE quoted_id=\"\"\n",
    "        AND quoted_user<>\"Anonymous\"\n",
    "        AND quoted_text<>\"\"\n",
    ") as q\n",
    "LEFT JOIN (\n",
    "    SELECT\n",
    "        p.thread_id,\n",
    "        p.post_count,\n",
    "        p.body,\n",
    "        u.name\n",
    "    FROM posts AS p\n",
    "    LEFT JOIN users AS u\n",
    "        ON p.user_url = u.user_url\n",
    ") as s\n",
    "    ON s.thread_id=q.thread_id\n",
    "        AND s.name=q.quoted_user\n",
    "        AND q.quoted_text=s.body\n",
    "        AND s.post_count<q.post_count\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network Links\n",
    "Loop through the netmums individual databases and match quotes to quoted posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_db = str(path_parent / \"database\" / )\n",
    "for i in range(1, 6):\n",
    "    path_db = str(path_parent / \"database\" / db)\n",
    "    db = \"netmums0{}.db\".format(i)\n",
    "    conn = create_connection(path_db)\n",
    "    quotes = pd.read_sql(quotes_sql, conn)\n",
    "    chunks = chunker(quotes.shape[0], chunk_size)\n",
    "    for chunk in chunks:\n",
    "        # slice quotes data frame\n",
    "        quotes_chunk = quotes.iloc[chunk[0]:chunk[1]].copy()\n",
    "        \n",
    "        # insert chunk into temporary table in database\n",
    "        cur.execute(drop_table_sql)\n",
    "        chunk.to_sql('temp', conn, index=False)\n",
    "        \n",
    "        # get matches\n",
    "        chunk_matches = pd.read_sql(chunk_matches_sql, conn)\n",
    "        \n",
    "        # add group sizes\n",
    "        chunk_matches['group_size'] = (\n",
    "            chunk_matches\n",
    "            .groupby(['q_thread_id','q_post_count','citation_n'])['s_thread_id']\n",
    "            .transform(len)\n",
    "        )\n",
    "        \n",
    "        # filter matches\n",
    "        chunk_matches = chunk_matches.loc[chunk_matches['group_size'] == 1]\n",
    "        \n",
    "        # write to table\n",
    "        chunk_matches = chunk_matches[[\n",
    "            'quoting_thread_id',\n",
    "            'quoting_post_count',\n",
    "            'quoted_thread_id',\n",
    "            'quoted_post_count'\n",
    "        ]]\n",
    "        chunk_matches.to_sql('quote_network', if_exists='append', conn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nonunique_matches['similarity'] = (\n",
    "    nonunique_matches\n",
    "    .apply(lambda x: get_jaccard_sim(\n",
    "        x.quoted_text,\n",
    "        x.body\n",
    "    ),\n",
    "           axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymous Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_posts = '''\n",
    "    SELECT\n",
    "        p.thread_id AS thread_id,\n",
    "        p.post_count AS post_count,\n",
    "        p.body AS body\n",
    "    FROM posts AS p\n",
    "    LEFT JOIN users AS u\n",
    "        ON p.user_url = u.user_url\n",
    "    WHERE\n",
    "        p.thread_id={0}\n",
    "        AND u.name=\"{1}\"\n",
    "        AND p.post_count<{2};\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_posts_anon = '''\n",
    "    SELECT\n",
    "        thread_id,\n",
    "        post_count,\n",
    "        body\n",
    "    FROM posts\n",
    "    WHERE\n",
    "        thread_id={0}\n",
    "        AND user_url=\"Anonymous\"\n",
    "        AND post_count<{1};\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
