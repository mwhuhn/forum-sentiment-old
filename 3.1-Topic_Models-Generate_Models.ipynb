{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Topic Models\n",
    "Generates the topic models of forum posts with LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "## Data Sources\n",
    "- corpus (created with 3.0-Topic_Models-Lemmatize_Text.ipynb)\n",
    "- dictionary (created with 3.0-Topic_Models-Lemmatize_Text.ipynb)\n",
    "- lemmatized_text (created with 3.0-Topic_Models-Lemmatize_Text.ipynb)\n",
    "\n",
    "## Changes\n",
    "- 2020-09-16: Created\n",
    "- 2020-09-17: Found topic model with highest coherence and generated dominant topics\n",
    "- 2020-12-19: Added new data\n",
    "\n",
    "## TODO\n",
    "- Tutorial\n",
    " - https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    " - https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n",
    "from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# Managing data\n",
    "import pandas as pd\n",
    "import re\n",
    "# DB connection\n",
    "from scraping import create_connection\n",
    "# Files & I/O\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import FileIO\n",
    "# For logging\n",
    "import logging\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For formatting LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list(fn, results):\n",
    "    with open(fn, 'a') as f:\n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_topics(topics):\n",
    "    return [t[1] for t in topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(forum=\"all\", group=\"all\", id_type=\"family_id\"):\n",
    "    lemmatized_text = pickle.load(open(path_lemma_pkl.format(forum, group, id_type), 'rb'))\n",
    "    corpus = pickle.load(open(path_corpus_pkl.format(forum, group, id_type), 'rb'))\n",
    "    dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(forum, group, id_type))\n",
    "    return lemmatized_text, corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_doc_convergence(log, i):\n",
    "    # Regex to bookend log for iteration - choose last occurrence\n",
    "#     end_slice = re.compile(fr\"End of model: {i} iterations\")\n",
    "#     end_matches = [end_slice.findall(l) for l in open(log)]\n",
    "#     iteration_end = [i for i, x in enumerate(end_matches) if x]\n",
    "#     iteration_end = iteration_end[-1]\n",
    "#     start_slice = re.compile(fr\"Start of model: {i} iterations\")\n",
    "#     start_matches = [start_slice.findall(l) for l in open(log)]\n",
    "#     start_options = [i for i, x in enumerate(start_matches) if x]\n",
    "#     start_options = [item for item in start_options if item < iteration_end]\n",
    "#     iteration_start = max(start_options)\n",
    "#     iteration_bookends = [iteration_start, iteration_end]\n",
    "    # Regex to find documents converged figures\n",
    "    num = re.compile(\":(\\d+)\\/\\d\")\n",
    "    matches_num = [num.findall(l) for l in open(log)]\n",
    "#     matches_num = matches_num[iteration_bookends[0]:iteration_bookends[1]]\n",
    "    matches_num = [m for m in matches_num if len(m) > 0]\n",
    "    # Unlist internal lists and turn into numbers\n",
    "    matches_num = [m for sublist in matches_num for m in sublist]\n",
    "    matches_num = [float(m) for m in matches_num]\n",
    "    # Regex to find documents converged figures\n",
    "    den = re.compile(\":\\d+\\/(\\d+)\")\n",
    "    matches_den = [den.findall(l) for l in open(log)]\n",
    "#     matches_den = matches_den[iteration_bookends[0]:iteration_bookends[1]]\n",
    "    matches_den = [m for m in matches_den if len(m) > 0]\n",
    "    # Unlist internal lists and turn into numbers\n",
    "    matches_den = [m for sublist in matches_den for m in sublist]\n",
    "    matches_den = [float(m) for m in matches_den]\n",
    "    return(matches_num, matches_den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "path_db = str(path_parent / \"database\" / \"youbemom-merged.db\")\n",
    "# data to load\n",
    "path_lemma_pkl = str(path_parent / \"clean_data\" / \"lemmatized_text_{0}_{1}_{2}.pkl\")\n",
    "path_corpus_pkl = str(path_parent / \"clean_data\" / \"corpus_{0}_{1}_{2}.pkl\")\n",
    "path_dictionary_gensim = str(path_parent / \"clean_data\" / \"dictionary_{0}_{1}_{2}.gensim\")\n",
    "# model saving\n",
    "path_tune_models = str(path_parent / \"clean_data\" / \"lda_tune_{0}_{1}_{2}_{3}_{4}.gensim\")\n",
    "path_ntopic_models = str(path_parent / \"clean_data\" / \"lda_ntopics_{0}_{1}_{2}_{3}.gensim\")\n",
    "# path_coherence = str(path_parent / \"clean_data\" / \"coherence_{}.csv\")\n",
    "path_log = str(path_parent / \"clean_data\" / \"logging_{0}_{1}_{2}_{3}.log\")\n",
    "path_log_iterations = str(path_parent / \"clean_data\" / \"logging_{0}_{1}_{2}_{3}.log\")\n",
    "# dominant topic\n",
    "path_dom_topic = str(path_parent / \"clean_data\" / \"dominant_topic_{0}_{1}_{2}_{3}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model for convergence\n",
    "Train an LDA model on all subforums and all posts grouped on family_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subforum = ['toddler'] # ['special-needs','tween-teen','preschool','elementary','new-york-city','toddler']\n",
    "group = 'all'\n",
    "id_type = 'family_id'\n",
    "n_words = 10\n",
    "n_passes = 30\n",
    "n_iterations = [200] # add more to list to test\n",
    "eval_every = 20\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 10 topics to evaluate number of passes and iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sf in subforum:\n",
    "    lemmatized_text, corpus, dictionary = load_data(sf, group, id_type)\n",
    "    for handler in logging.root.handlers:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(filename=path_log.format(sf, group, id_type, n),\n",
    "                        format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                        level=logging.NOTSET)\n",
    "    perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "    convergence_logger = ConvergenceMetric(logger='shell')\n",
    "    coherence_cv_logger = CoherenceMetric(corpus=corpus, logger='shell', coherence = 'c_v', texts = lemmatized_text)\n",
    "    for iterations in n_iterations:\n",
    "        logging.debug(f'Start of model: {iterations} iterations')\n",
    "        ldamodel = LdaModel(\n",
    "            corpus=corpus,\n",
    "            num_topics=n,\n",
    "            id2word=dictionary,\n",
    "            passes=n_passes,\n",
    "            alpha=\"auto\",\n",
    "            eta=\"auto\",\n",
    "            random_state=1,\n",
    "            iterations=iterations,\n",
    "            eval_every=eval_every,\n",
    "            callbacks=[perplexity_logger, convergence_logger, coherence_cv_logger]\n",
    "        )\n",
    "        logging.debug(f'End of model: {iterations} iterations')\n",
    "        ldamodel.save(path_tune_models.format(sf, group, id_type, str(n), str(iterations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart convergence of 10 topics\n",
    "see: https://www.meganstodel.com/posts/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = \"toddler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LdaModel.load(path_tune_models.format(sf, group, id_type, str(n), str(200)))\n",
    "df = pd.DataFrame.from_dict(ldamodel.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index, df[\"Convergence\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.index, df[\"Coherence\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(df.index, df[\"Perplexity\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_num, con_den = find_doc_convergence(path_log.format(sf, group, id_type, n), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(con_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_points = list(range(37)) * 198\n",
    "epochs = [i for i in range(198) for _ in range(37)]\n",
    "convergence = pd.DataFrame(list(zip(epochs, eval_points, con_num, con_den)),\n",
    "                               columns = [\"epoch\",\"eval_point\",\"converged\",\"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convergence['epoch_point'] = convergence['epoch'] + convergence['eval_point'] / 13\n",
    "convergence['per_converged'] = convergence['converged'] / convergence['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(convergence['epoch_point'], convergence['per_converged'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For special needs: after testing 10, 100, and 200 iterations, we need at least 200 for the docs made from threads (grouped on family_id) to converge. 100 passes seems to let the convergence, perplexity, and coherence converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through different topic counts to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 'toddler'\n",
    "group = 'all'\n",
    "id_type = 'family_id'\n",
    "n_words = 10\n",
    "n_passes = 35\n",
    "n_iterations = 200\n",
    "n_topics = [5, 10, 15, 20, 25, 30, 40, 50]\n",
    "# n_topics = [40, 50]\n",
    "eval_every = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text, corpus, dictionary = load_data(sf, group, id_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_topics:\n",
    "    print(\"number of topics: \", n)\n",
    "    ldamodel = LdaModel(\n",
    "        corpus=corpus,\n",
    "        num_topics=n,\n",
    "        id2word=dictionary,\n",
    "        passes=n_passes,\n",
    "        alpha=\"auto\",\n",
    "        eta=\"auto\",\n",
    "        random_state=1,\n",
    "        iterations=n_iterations,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "    ldamodel.save(path_ntopic_models.format(sf, group, id_type, str(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_topics = str(path_parent / \"clean_data\" / \"lda_topics_{0}_{1}_{2}.csv\")\n",
    "write_list(path_topics.format(sf, group, id_type), [\"n_topics\",\"topic_n\",\"topics\"])\n",
    "for n in n_topics:\n",
    "    ldamodel = LdaModel.load(path_ntopic_models.format(sf, group, id_type, str(n)))\n",
    "    topics = ldamodel.print_topics(num_topics=n, num_words=n_words)\n",
    "    for topic in topics:\n",
    "        write_list(path_topics.format(sf, group, id_type), [n, topic[0], topic[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ldamodel = LdaModel.load(path_tune_models.format(forum, group, str(10)))\n",
    "ldamodel.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find dominant topics for each message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data used to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping import create_connection\n",
    "from lemmatize import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df of clean text from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each n topic, find dominant topic in each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_topics:\n",
    "    ldamodel = LdaModel.load(path_tune_models.format(forum, group, str(n)))\n",
    "    topic_sentences = format_topics_sentences(ldamodel, corpus)\n",
    "    df_joined = pd.concat([df.reset_index(drop=True), topic_sentences.reset_index(drop=True)], axis=1)\n",
    "    df_joined[[\"message_id\",\"text_clean\",\"Dominant_Topic\",\"Perc_Contribution\"]].to_csv(path_dom_topic.format(forum, group, str(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dominant = pd.DataFrame()\n",
    "topic_grouped = df_joined.groupby('Dominant_Topic')\n",
    "for i, grp in topic_grouped:\n",
    "    topic_dominant = pd.concat([topic_dominant,\n",
    "                                grp.sort_values(['Perc_Contribution'],\n",
    "                                                ascending=[0]).head(3)],\n",
    "                               axis=0)\n",
    "topic_dominant.reset_index(drop=True, inplace=True)\n",
    "topic_dominant.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dominant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in topic_dominant['text_clean']:\n",
    "    print(t)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot differences between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_plotly(mdiff, title=\"\", annotation=None):\n",
    "    \"\"\"Plot the difference between models.\n",
    "\n",
    "    Uses plotly as the backend.\"\"\"\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.offline as py\n",
    "\n",
    "    annotation_html = None\n",
    "    if annotation is not None:\n",
    "        annotation_html = [\n",
    "            [\n",
    "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "                for (int_tokens, diff_tokens) in row\n",
    "            ]\n",
    "            for row in annotation\n",
    "        ]\n",
    "\n",
    "    data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
    "    layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
    "    py.iplot(dict(data=[data], layout=layout))\n",
    "\n",
    "\n",
    "def plot_difference_matplotlib(mdiff, title=\"\", annotation=None):\n",
    "    \"\"\"Helper function to plot difference between models.\n",
    "\n",
    "    Uses matplotlib as the backend.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(data)\n",
    "\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "    import plotly.offline as py\n",
    "except Exception:\n",
    "    #\n",
    "    # Fall back to matplotlib if we're not in a notebook, or if plotly is\n",
    "    # unavailable for whatever reason.\n",
    "    #\n",
    "    plot_difference = plot_difference_matplotlib\n",
    "else:\n",
    "    py.init_notebook_mode()\n",
    "    plot_difference = plot_difference_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel5 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(5)))\n",
    "ldamodel10 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(10)))\n",
    "ldamodel15 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(15)))\n",
    "ldamodel20 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(20)))\n",
    "ldamodel25 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(25)))\n",
    "ldamodel30 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(30)))\n",
    "ldamodel40 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(40)))\n",
    "ldamodel50 = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdiff, annotation = ldamodel10.diff(ldamodel5, distance=\"hellinger\", num_words=50)\n",
    "plot_difference(mdiff, title=\"topic difference\", annotation=annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the topics. See: https://www.objectorientedsubject.net/2018/08/experiments-on-topic-modeling-pyldavis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Dominant Topic in each Post?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamodel, corpus=corpus)\n",
    "df_topic_sents_keywords.info()\n",
    "df_topic_sents_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "path_db = str(path_parent / \"database\" / \"youbemom-merged.db\")\n",
    "sql = '''\n",
    "    SELECT s.text_no_url AS text_no_url, s.text as text\n",
    "    FROM sentiment AS s\n",
    "    JOIN posts AS p\n",
    "    ON s.message_id = p.message_id\n",
    "    WHERE p.subforum=\"special-needs\" AND p.parent_id=\"\"\n",
    "'''\n",
    "conn = create_connection(path_db)\n",
    "sn = pd.read_sql_query(sql, conn)\n",
    "sn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Topics and Keywords in New Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(path_db)\n",
    "df_topic_sents_keywords.to_sql('topicmodel', conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
