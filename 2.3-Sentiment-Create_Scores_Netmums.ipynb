{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentiment for Netmums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pathlib import Path\n",
    "from scraping import create_connection\n",
    "from tqdm.notebook import tqdm\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]\n",
    "path_db = str(path_parent / \"database\" / \"netmums-merged.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(conn):\n",
    "    \"\"\" gets the size of the data set in number of rows\n",
    "    :param conn: connection the the db\n",
    "    :return size: size of the posts table\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(''' SELECT COUNT(id) FROM posts ''')\n",
    "    size = cur.fetchone()\n",
    "    if size:\n",
    "        return int(size[0])\n",
    "    raise SystemExit(\"No size found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(chunksize):\n",
    "    \"\"\" read data in chunks from the table, format the text,\n",
    "        apply the sentiemnt analyzer, and write chunks to \n",
    "        the sentiment table\n",
    "    :param chunksize: size of chunks\n",
    "    \"\"\"\n",
    "    sql = ''' SELECT * FROM text '''\n",
    "    reader = pd.read_sql_query(sql,\n",
    "                               conn,\n",
    "                               chunksize=chunksize)\n",
    "    for i, df in enumerate(tqdm(reader)):\n",
    "        df = gen_sentiment(df, 'text_clean', 'clean')\n",
    "        df.drop('text_clean', axis=1, inplace=True)\n",
    "        if i == 0:\n",
    "            df.to_sql('sentiment', conn, if_exists='replace', index=False)\n",
    "        else:\n",
    "            df.to_sql('sentiment', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sentiment(df, var, name):\n",
    "    \"\"\" apply the sentiment score to the input var\n",
    "    :param var: string name of column getting sentiment for\n",
    "    :param name: string variable suffix\n",
    "    :return score: a dictionary of scores (neg, neu, pos, compound)\n",
    "    \"\"\"\n",
    "    sentiment = df[var].apply(lambda x: sentiment_scores(x, analyzer))\n",
    "    name_neg = \"neg_sen_{}\".format(name)\n",
    "    name_neu = \"neu_sen_{}\".format(name)\n",
    "    name_pos = \"pos_sen_{}\".format(name)\n",
    "    name_com = \"com_sen_{}\".format(name)\n",
    "    df[name_neg] = sentiment.apply(lambda x: x.get('neg', 0))\n",
    "    df[name_neu] = sentiment.apply(lambda x: x.get('neu', 0))\n",
    "    df[name_pos] = sentiment.apply(lambda x: x.get('pos', 0))\n",
    "    df[name_com] = sentiment.apply(lambda x: x.get('compound', 0))\n",
    "    del sentiment\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence, analyzer):\n",
    "    \"\"\" create sentiment scores with the VADER analyzer\n",
    "    :param sentence: sentence to create scores for\n",
    "    :param analyzer: VADER sentiment analyzer\n",
    "    :return score: a dictionary of scores (neg, neu, pos, compound)\n",
    "    \"\"\"\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)\n",
    "size = get_size(conn)\n",
    "nchunks = 200\n",
    "chunksize = floor(size / nchunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee29d0d2c9441bab99cce77e0b272c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data(chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
